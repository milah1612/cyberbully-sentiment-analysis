# -*- coding: utf-8 -*-
"""Twitter_Sentiment_Analysis_(1) (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T0aMqhcPu7kHqjGoqPaCgGu53ZTp5ZIN
"""

!pip install emoji
!pip install langdetect
!pip install contractions
!pip install nltk

# Libraries for general purpose
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import nltk

# Text cleaning
import re
import string
import emoji
import nltk
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet') #NLP processing
from nltk.stem import WordNetLemmatizer, PorterStemmer
from nltk.corpus import stopwords
from string import punctuation


# Data preprocessing
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import RandomOverSampler
from langdetect import detect, LangDetectException
import contractions
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import CountVectorizer
from IPython.display import display
from tabulate import tabulate

#EDA
from textblob import TextBlob
from wordcloud import WordCloud
from collections import Counter

"""# `Dataset'

"""

#import dataset
df = pd.read_csv("cyberbullying_tweets.csv")

#display first 5 rows in dataset
df.head()

#dispaly data type and sum
df.info()

print("cyberbullying tweet set shape: {}". format(df.shape))

"""# Data Cleaning"""

#Display total of duplicate value
df.duplicated().sum()

#Removing the duplicate values
df = df[~df.duplicated()]

#check again duplicate value after drop
df.duplicated().sum()

#Check missing value
df.isnull().sum()

#total after duplicate removal 47692 - 47656 = 36
df.info()

df = df.rename(columns={'tweet_text' : 'tweets', 'cyberbullying_type': 'cyberbullyType'})

df.cyberbullyType.value_counts()

#tweets labelled as other have been removed. This class is unbalance and unable to label compare to other classes.
#after dropping class, display the remaining class
df = df[df["cyberbullyType"]!="other_cyberbullying"]
df.cyberbullyType.value_counts()

class_mapping = {
    'age': 'minor',
    'ethnicity': 'racism'
}
df['cyberbullyType'] = df['cyberbullyType'].replace(class_mapping)

df.cyberbullyType.value_counts()

# emoji_pattern = re.compile("["
#                            u"\U0001F600-\U0001F64F"  # emoticons
#                            u"\U0001F300-\U0001F5FF"  # symbols & pictographs
#                            u"\U0001F680-\U0001F6FF"  # transport & map symbols
#                            u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
#                            u"\U00002500-\U00002BEF"  # chinese char
#                            u"\U00002702-\U000027B0"
#                            u"\U00002702-\U000027B0"
#                            u"\U000024C2-\U0001F251"
#                            u"\U0001f926-\U0001f937"
#                            u"\U00010000-\U0010ffff"
#                            u"\u2640-\u2642"
#                            u"\u2600-\u2B55"
#                            u"\u200d"
#                            u"\u23cf"
#                            u"\u23e9"
#                            u"\u231a"
#                            u"\ufe0f"  # dingbats
#                            u"\u3030"
#                            ":p"                   # Add :p emoji
#                            "]+", flags=re.UNICODE)

# # Check for emojis in the tweet_text column
# df['has_emoji'] = df['tweets'].apply(lambda x: bool(emoji_pattern.search(x)))


# # Display the DataFrame
# print(df[['tweets', 'has_emoji']])

# # Count the number of tweets with and without emojis
# emoji_counts = df['has_emoji'].value_counts()

# # Plot
# plt.figure(figsize=(8, 6))
# bars = emoji_counts.plot(kind='bar', color=['skyblue', 'lightcoral'])
# plt.title('Number of Tweets with and without Emojis')
# plt.xlabel('Has Emoji')
# plt.ylabel('Count')
# plt.xticks([0, 1], ['No', 'Yes'], rotation=0)

# # Annotate bars with count values
# for i in range(len(emoji_counts)):
#     plt.text(i, emoji_counts[i], str(emoji_counts[i]), ha='center', va='bottom')

# plt.show()

# Clean emojis from text
def strip_emoji(text):
    return emoji.demojize(text)

# Remove punctuations, stopwords, links, mentions and new line characters
def strip_all_entities(text, stop_words):
    text = re.sub(r'\r|\n', ' ', text.lower())  # Replace newline and carriage return with space, and convert to lowercase
    text = re.sub(r"(?:\@|https?\://)\S+", "", text)  # Remove links and mentions
    text = re.sub(r'[^\x00-\x7f]', '', text)  # Remove non-ASCII characters
    banned_list = string.punctuation
    table = str.maketrans('', '', banned_list)
    text = text.translate(table)
    text = ' '.join(word for word in text.split() if word not in stop_words)
    return text

# Filter special characters such as & and $ present in some words
def filter_chars(text):
    return ' '.join('' if ('$' in word) or ('&' in word) else word for word in text.split())

# Remove multiple spaces
def remove_mult_spaces(text):
    return re.sub(r"\s\s+", " ", text)

# Function to check if the text is in English, and return an empty string if it's not
def filter_non_english(text):
    try:
        lang = detect(text)
    except LangDetectException:
        lang = "unknown"
    return text if lang == "en" else ""

# Apply the filter_non_english function to your text data
df['text_clean'] = df['tweets'].apply(filter_non_english)

# Expand contractions
def expand_contractions(text):
    return contractions.fix(text)

# Remove numbers
def remove_numbers(text):
    return re.sub(r'\d+', '', text)

# Lemmatize words
def lemmatize(text):
   lemmatizer = WordNetLemmatizer()  # Initialize the lemmatizer
   words = word_tokenize(text)
   lemmatized_words = [lemmatizer.lemmatize(word) for word in words]
   return ' '.join(lemmatized_words)

# Remove short words
def remove_short_words(text, min_len=2):
    words = text.split()
    long_words = [word for word in words if len(word) >= min_len]
    return ' '.join(long_words)

# Replace elongated words with their base form
def replace_elongated_words(text):
    regex_pattern = r'\b(\w+)((\w)\3{2,})(\w*)\b'
    return re.sub(regex_pattern, r'\1\3\4', text)

# Remove repeated punctuation
def remove_repeated_punctuation(text):
    return re.sub(r'[\?\.\!]+(?=[\?\.\!])', '', text)

# Remove extra whitespace
def remove_extra_whitespace(text):
    return ' '.join(text.split())

def remove_url_shorteners(text):
    return re.sub(r'(?:http[s]?://)?(?:www\.)?(?:bit\.ly|goo\.gl|t\.co|tinyurl\.com|tr\.im|is\.gd|cli\.gs|u\.nu|url\.ie|tiny\.cc|alturl\.com|ow\.ly|bit\.do|adoro\.to)\S+', '', text)

# Remove spaces at the beginning and end of the tweet
def remove_spaces_tweets(tweet):
    return tweet.strip()

# Remove short tweets
def remove_short_tweets(tweet, min_words=3):
    words = tweet.split()
    return tweet if len(words) >= min_words else ""

#Define stop words
stop_words = set(stopwords.words('english'))

# Function to call all the cleaning functions in the correct order
def clean_tweet(tweet, stop_words):
    tweet = strip_emoji(tweet)
    tweet = expand_contractions(tweet)
    tweet = filter_non_english(tweet)
    tweet = strip_all_entities(tweet, stop_words)
    tweet = filter_chars(tweet)
    tweet = remove_mult_spaces(tweet)
    tweet = remove_numbers(tweet)
    tweet = lemmatize(tweet)
    tweet = remove_short_words(tweet)
    tweet = replace_elongated_words(tweet)
    tweet = remove_repeated_punctuation(tweet)
    tweet = remove_extra_whitespace(tweet)
    tweet = remove_url_shorteners(tweet)
    tweet = remove_spaces_tweets(tweet)
    tweet = remove_short_tweets(tweet)
    tweet = ' '.join(tweet.split())  # Remove multiple spaces between words
    return tweet

stop_words = set(stopwords.words('english'))

# Apply clean_tweet function to each tweet in 'tweets' column and store cleaned text in 'text_clean' column
df['text_clean'] = df['tweets'].apply(lambda tweet: clean_tweet(tweet, stop_words))

# Display the first few rows of the DataFrame
df.head(20)

#check duplicates after cleaning
print(f'There are around {int(df["text_clean"].duplicated().sum())} duplicated tweets')

df.drop_duplicates("text_clean", inplace=True)
df.cyberbullyType.value_counts()

#check duplicates after dropping duplicates
print(f'There are around {int(df["text_clean"].duplicated().sum())} duplicated tweets')

# Check for empty values in the 'tweets' column
empty_tweets = df[df['tweets'].isnull()]

# Check for empty values in the 'cyberbullyType' column
empty_cyberbullyType = df[df['cyberbullyType'].isnull()]

# Check for empty values in the 'text_clean' column
empty_text_clean = df[df['text_clean'].isnull()]

print(empty_tweets)
print(empty_cyberbullyType)
print(empty_text_clean)

df.head(20)

# # Extract hashtags and their frequencies
# hashtags = df['tweets'].str.findall(r'#(\w+)')  # Extract hashtags from the original tweet text
# hashtags = [tag.lower() for sublist in hashtags for tag in sublist]  # Convert hashtags to lowercase
# hashtags_df = pd.DataFrame(hashtags, columns=['Hashtag'])  # Create DataFrame
# hashtags_df['Frequency'] = 1  # Add Frequency column
# hashtags_df = hashtags_df.groupby('Hashtag').count().reset_index().sort_values(by='Frequency', ascending=False)  # Count frequencies

# # Plot top hashtags
# plt.figure(figsize=(12, 6))
# top_hashtags = hashtags_df[:20]
# ax = sns.barplot(x='Frequency', y='Hashtag', data=top_hashtags)
# plt.title('Top 20 Hashtags')
# plt.xlabel('Frequency')
# plt.ylabel('Hashtag')
# for index, value in enumerate(top_hashtags['Frequency']):
#     ax.text(value, index, str(value))
# plt.show()

# #MKR (My Kitchen Rules 2015. It breaks tweet record of other shows.)

df.info()

# Length of tweets
plt.figure(figsize=(10, 5))
df['tweet_length'] = df['text_clean'].apply(len)
df['tweet_length'].plot(kind='hist', alpha=0.5, bins=range(0, 201, 10), legend=True)
plt.title('Tweet Length Distribution')
plt.xlabel('Tweet Length')
plt.ylabel('Count')
plt.show()

# DO NOT RUN THIS CODE AS IT GENERATE DUPLICATE COLUMN FOR TWEET LENGTH

# # Filter out tweets that are too long (with more than 100 words).
# df.loc[:, 'text_len'] = [len(text.split()) for text in df['text_clean']]
# df = df[df['text_len'] < df['text_len'].quantile(0.995)]
# # Calculate the maximum length of the text after filtering
# max_len = df['text_len'].max()

# # Print the maximum length of the text
# print("Maximum length of text after filtering:", max_len)

Q1 = df['tweet_length'].quantile(0.25)
Q3 = df['tweet_length'].quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

outliers = df[(df['tweet_length'] < lower_bound) | (df['tweet_length'] > upper_bound)]
print("Lower Bound:", lower_bound)
print("Upper Bound:", upper_bound)

if outliers.empty:
    print("No outliers found.")
else:
    print("Outliers:")
    print(outliers)

# Create a box plot to visualize tweet lengths
plt.figure(figsize=(8, 6))
sns.boxplot(x=df['tweet_length'])
plt.title('Distribution of Tweet Lengths')
plt.xlabel('Tweet Length')
plt.show()

# Calculate lower and upper bounds
lower_bound = df['tweet_length'].quantile(0.005)
upper_bound = df['tweet_length'].quantile(0.995)

# Filter out the tweets with outlier lengths
df = df[(df['tweet_length'] >= lower_bound) & (df['tweet_length'] <= upper_bound)]

# Check if all tweets fall within the acceptable range
all_within_bounds = df['tweet_length'].between(lower_bound, upper_bound).all()

# Print the result
print("Lower Bound:", lower_bound)
print("Upper Bound:", upper_bound)

if all_within_bounds:
    print("No outliers found.")
else:
    print("Tweets outside the acceptable range:")
    print(df[(df['tweet_length'] < lower_bound) | (df['tweet_length'] > upper_bound)])

# Create a box plot to visualize tweet lengths
plt.figure(figsize=(8, 6))
sns.boxplot(x=df['tweet_length'])
plt.title('Distribution of Tweet Lengths')
plt.xlabel('Tweet Length')
plt.show()

"""# EDA Processing

Labelling each classes
"""

# cyberbullyType = ["religion","age","ethnicity","gender","not bullying"]
# label_mapping = {'religion':0,'age':1,'ethnicity':2,'gender':3,'not_cyberbullying':4}
# df['cyberbullyType'] = df['cyberbullyType'].map(label_mapping)

# Define the label mapping dictionary
label_mapping = {'religion': 0, 'minor': 1, 'racism': 2, 'gender': 3, 'not_cyberbullying': 4}

# Create a new column with numerical labels based on the existing 'cyberbullyType' column
df.insert(df.columns.get_loc('cyberbullyType') + 1, 'cyberbullyType_label', df['cyberbullyType'].map(label_mapping))

df.head(100)

# Assuming 'class_label' is the column containing class labels
class_counts = df['cyberbullyType_label'].value_counts()

# Reorder index
class_counts = class_counts.sort_index()

# Define colors for each bar
colors = ['blue', 'green', 'orange', 'red', 'purple']

# Plot bar chart
plt.figure(figsize=(8, 6))
class_counts.plot(kind='bar', color=colors)
plt.title('Distribution of Class Labels')
plt.xlabel('Label')
plt.ylabel('Count')
plt.xticks(rotation=45)


# Add count numbers on top of each bar
for i, count in enumerate(class_counts):
    plt.text(i, count + 0.1, str(count), ha='center', va='bottom')

# Add class labels under each bar
class_labels = ['Religion', 'Minor', 'Racism', 'Gender', 'Not Cyberbullying']
plt.xticks(range(len(class_labels)), class_labels, rotation=45)

plt.show()

#Display new column for cyberbullyType_label
df.tail(10)

"""Sentiment Analysis"""

# Function for sentiment analysis
def analyze_sentiment(text):
    analysis = TextBlob(text)
    # Get the polarity score (1 for negative, 0 for positive)
    polarity = analysis.sentiment.polarity
    # Classify the sentiment based on polarity score
    if polarity > 0:
        sentiment = 'positive'
    elif polarity < 0:
        sentiment = 'negative'
    else:
        sentiment = None
    return sentiment

# Apply sentiment analysis to the 'text_clean' column
df['sentiment'] = df['text_clean'].apply(analyze_sentiment)

# Remove rows with neutral sentiment
df = df[df['sentiment'].notnull()]

df.head(10)

# # Create a pivot table to calculate the frequency distribution of sentiments across cyberbully types
# pivot_table = df.pivot_table(index='cyberbullyType_label', columns='sentiment', aggfunc='size', fill_value=0)

# # Plot the heatmap
# plt.figure(figsize=(10, 6))
# sns.heatmap(pivot_table, annot=True, cmap="YlGnBu", fmt="d")
# plt.title('Frequency Distribution of Sentiments Across Cyberbully Types')
# plt.xlabel('Sentiment')
# plt.ylabel('Cyberbully Type')
# plt.show()

"""Word Cloud"""

# Assuming you have separate text data for negative and positive sentiments
negative_text = " ".join(df[df['sentiment'] == 'negative']['text_clean'])
positive_text = " ".join(df[df['sentiment'] == 'positive']['text_clean'])

# Generate word clouds for negative sentiment
wordcloud_negative = WordCloud(width=800, height=400, background_color='white').generate(negative_text)

# Generate word clouds for positive sentiment
wordcloud_positive = WordCloud(width=800, height=400, background_color='white').generate(positive_text)

# Word cloud for positive tweets
positive_tweets = df[df['sentiment'] == 'positive']['text_clean'].str.cat(sep=' ')
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(positive_tweets)
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.title('Word Cloud for Positive Tweets')
plt.axis('off')
plt.show()

# Word cloud for negative tweets
negative_tweets = df[df['sentiment'] == 'negative']['text_clean'].str.cat(sep=' ')
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(negative_tweets)
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.title('Word Cloud for Negative Tweets')
plt.axis('off')
plt.show()

# Function to extract and count hashtags
def extract_hashtags(sentiment):
    hashtags = df[df['sentiment'] == sentiment]['tweets'].str.findall(r'#(\w*[a-zA-Z]+\w*)')
    hashtags_flat = [re.sub(r'\d+', '', tag.lower()) for sublist in hashtags for tag in sublist]
    return pd.Series(hashtags_flat).value_counts()

# Extract and count positive hashtags
positive_hashtags_count = extract_hashtags('positive')

# Extract and count negative hashtags
negative_hashtags_count = extract_hashtags('negative')

# Display the top 10 positive and negative hashtags
print("\nPositive Hashtags:")
print(positive_hashtags_count.head(20))
print("\nNegative Hashtags:")
print(negative_hashtags_count.head(20))

# Plot positive hashtags
plt.figure(figsize=(10, 6))
positive_hashtags_count.head(20).sort_values().plot(kind='barh', color='skyblue')
plt.title('Top 20 Positive Hashtags')
plt.xlabel('Frequency')
plt.ylabel('Hashtag')
plt.show()

# Plot negative hashtags
plt.figure(figsize=(10, 6))
negative_hashtags_count.head(20).sort_values().plot(kind='barh', color='salmon')
plt.title('Top 20 Negative Hashtags')
plt.xlabel('Frequency')
plt.ylabel('Hashtag')
plt.show()

# Plot tweet length distribution for positive sentiment
plt.figure(figsize=(10, 5))
df[df['sentiment'] == 'positive']['tweet_length'].plot(kind='hist', alpha=0.5, bins=20, color='blue', label='Positive')
plt.title('Tweet Length Distribution - Positive Sentiment')
plt.xlabel('Tweet Length')
plt.ylabel('Count')
plt.legend()
plt.show()

# Plot tweet length distribution for negative sentiment
plt.figure(figsize=(10, 5))
df[df['sentiment'] == 'negative']['tweet_length'].plot(kind='hist', alpha=0.5, bins=20, color='red', label='Negative')
plt.title('Tweet Length Distribution - Negative Sentiment')
plt.xlabel('Tweet Length')
plt.ylabel('Count')
plt.legend()
plt.show()

# # Get the text from the tweet_text column
# text = df['text_clean']

# # Split the text into individual words
# words = text.str.split()

# # Flatten the list of words
# words = [word for sublist in words for word in sublist]

# # Get the unique words and their counts
# word_counts = pd.Series(words).value_counts()

# # Plot the top 10 most frequent words
# plt.figure(figsize=(18, 10))
# word_counts.head(20).plot(kind='bar')
# plt.title('Top 20 Keyword')
# plt.xlabel('Word')
# plt.ylabel('Frequency')
# plt.xticks(rotation=45)
# plt.show()



# Get the text from the tweet_text column
text = df['text_clean']

# Split the text into individual words
words = text.str.split()

# Flatten the list of words
words = [word for sublist in words for word in sublist]

# Get the unique words and their counts
word_counts = pd.Series(words).value_counts()

# Extract top 20 keywords
top_keywords = word_counts.head(20).index

# Create a DataFrame to store the count of each keyword for positive and negative sentiments
keyword_sentiments = pd.DataFrame(index=top_keywords, columns=['Positive', 'Negative'])

# Iterate over the keywords and count the occurrences in positive and negative sentiments
for keyword in top_keywords:
    positive_count = df[df['text_clean'].str.contains(keyword) & (df['sentiment'] == 'positive')].shape[0]
    negative_count = df[df['text_clean'].str.contains(keyword) & (df['sentiment'] == 'negative')].shape[0]
    keyword_sentiments.loc[keyword, 'Positive'] = positive_count
    keyword_sentiments.loc[keyword, 'Negative'] = negative_count

# Plot the top keywords against sentiment analysis
plt.figure(figsize=(18, 10))
keyword_sentiments.plot(kind='bar', color=['blue', 'red'])
plt.title('Top 20 Keywords by Sentiment')
plt.xlabel('Keyword')
plt.ylabel('Frequency')
plt.xticks(rotation=45)
plt.legend(title='Sentiment')
plt.tight_layout()  # Adjust layout to fit x-axis labels properly
plt.show()

# # List of bad words
# negative_words = ['nigga', 'bitch', 'asshole', 'fuck', 'shit', 'bully', 'racist', 'suicide', 'die', 'killyourself', 'porn']

# # List of good words
# positive_words = ['love', 'happy', 'great', 'awesome', 'wonderful', 'blessed']

# def check_for_bad_words(text):
#     for word in negative_words:
#         if word in text:
#             return word
#     return None

# # Apply the function to the tweet_text column
# df['negative_word'] = df['text_clean'].apply(check_for_negative_words)

# # Get the frequency of bad words
# negative_word_frequency = df['negative_word'].value_counts()


# # Plot bad word frequency
# plt.figure(figsize=(10, 6))
# negative_word_frequency.plot(kind='bar', color='coral')
# plt.title('Frequency of Negative Words')
# plt.xlabel('Negative Words')
# plt.ylabel('Frequency')
# plt.xticks(rotation=45)

# # Add numbers on top of the bars
# for i, v in enumerate(negative_word_frequency):
#     ax.text(i, v + 0.2, str(v), ha='center', va='bottom')
# plt.show()

# ## Display the frequency of egative words print(negative_word_frequency)



# List of bad words
negative_words = ['nigga', 'bitch', 'asshole', 'fuck', 'shit', 'bully', 'racist', 'suicide', 'die', 'killyourself', 'porn']

# Function to check for negative words
def check_for_negative_words(text):
    for word in negative_words:
        if word in text:
            return word
    return None

# Apply the function to the text_clean column
df['negative_word'] = df['text_clean'].apply(check_for_negative_words)

# Get the frequency of negative words
negative_word_frequency = df['negative_word'].value_counts()

# Plot the frequency of negative words
plt.figure(figsize=(10, 6))
negative_word_frequency.plot(kind='bar', color='coral')
plt.title('Frequency of Negative Words')
plt.xlabel('Negative Words')
plt.ylabel('Frequency')
plt.xticks(rotation=45)

# Add numbers on top of the bars
for i, v in enumerate(negative_word_frequency):
    plt.text(i, v + 0.2, str(v), ha='center', va='bottom')

plt.tight_layout()
plt.show()

# Define negative bigrams
vectorizer = CountVectorizer(ngram_range=(2, 2))
negative_bigrams = vectorizer.fit_transform(df[df['sentiment'] == 'negative']['text_clean'])
negative_bigram_freq = pd.DataFrame(negative_bigrams.sum(axis=0), columns=vectorizer.get_feature_names_out())
negative_bigram_freq = negative_bigram_freq.T.sort_values(0, ascending=False).head(20)

# Plot the top 20 negative bigrams
plt.figure(figsize=(10, 8))
sns.barplot(x=negative_bigram_freq[0], y=negative_bigram_freq.index, hue=negative_bigram_freq.index, palette="Reds_d", legend=False)
plt.title('Top 20 Bi-grams in Negative Tweets')
plt.xlabel('Frequency')
plt.ylabel('Bi-grams')
plt.show()

"""Keyword Analysis"""

#Specify the file path where you want to save the CSV file
# file_path = r'C\Users\USER\Desktop\WQD7001 PRINCIPLES OF DATA SCIENCE\Assignment\cleaned_data.csv'
# Use the to_csv() method to save the DataFrame to a CSV file
# df.to_csv(file_path, index=False)
# df.to_csv(file_path)

df.to_csv("Users.csv")

"""# Feature Engineering
Extract relevant features from the cleaned text data or create new features if necessary.

For feature engineering, we'll use TF-IDF (Term Frequency-Inverse Document Frequency) to convert the text data into numerical features.
"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Initialize TF-IDF vectorizer
tfidf_vectorizer = TfidfVectorizer(max_features=30000)  # You can adjust max_features as needed

# Fit TF-IDF vectorizer and transform the 'text_clean' column
X_tfidf = tfidf_vectorizer.fit_transform(df['text_clean'])

# Convert the TF-IDF matrix into a DataFrame for easier handling
tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())

# Display the TF-IDF DataFrame
print(tfidf_df.head())

"""# Split Data
Split the dataset into training and testing sets.
"""

from sklearn.model_selection import train_test_split

X = df['text_clean']  # Features
y = df['sentiment']  # Target variable

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# Model Selection & Training
We'll choose a few common machine learning models for classification: Logistic Regression, Multinomial Naive Bayes, Support Vector Machine (SVM), Random Forest, and Gradient Boosting.
"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier



# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df['sentiment'], test_size=0.2, random_state=42)

# Initialize models
models = {
    'Logistic Regression': LogisticRegression(),
    'Naive Bayes': MultinomialNB(),
    'SVM': SVC(kernel='linear', probability=True),
    'Random Forest': RandomForestClassifier(),
    'Gradient Boosting': GradientBoostingClassifier()
}

# Train models
for name, model in models.items():
    model.fit(X_train, y_train)

# Evaluate models
for name, model in models.items():
    y_pred = model.predict(X_test)
    print(f"Classification Report for {name}:")
    print(classification_report(y_test, y_pred))

"""# Model Evaluation
We'll evaluate the models using accuracy and F1-score.
"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Define lists to store evaluation metrics
model_names = []
accuracy_scores = []
precision_scores = []
recall_scores = []
f1_scores = []

# Evaluate models
for name, model in models.items():
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    confusion = confusion_matrix(y_test, y_pred)

    # Append evaluation metrics to lists
    model_names.append(name)
    accuracy_scores.append(accuracy)
    precision_scores.append(precision)
    recall_scores.append(recall)
    f1_scores.append(f1)

    # Print evaluation metrics
    print(f"Evaluation metrics for {name}:")
    print(f"Accuracy: {accuracy}")
    print(f"Precision: {precision}")
    print(f"Recall: {recall}")
    print(f"F1-score: {f1}")
    print(f"Confusion Matrix:\n{confusion}\n")

# Create a DataFrame to display evaluation metrics
evaluation_df = pd.DataFrame({
    'Model': model_names,
    'Accuracy': accuracy_scores,
    'Precision': precision_scores,
    'Recall': recall_scores,
    'F1-score': f1_scores
})

# Display the DataFrame
print("Model Evaluation Metrics:")
print(evaluation_df)

"""## ROC CURVE AND PRECISION-RECALL CURVE  
These scores indicate that the SVM model performs the best among the models evaluated in terms of both ROC AUC and PR AUC.
"""

from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, auc
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelBinarizer

# Define lists to store ROC and PR AUC scores
roc_auc_scores = []
pr_auc_scores = []

# Initialize subplots for ROC and PR curves
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))

# Evaluate models
for name, model in models.items():
    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probability of positive class
    y_pred = model.predict(X_test)

    # Convert categorical labels to binary labels
    label_binarizer = LabelBinarizer()
    y_test_bin = label_binarizer.fit_transform(y_test)

    # Compute ROC curve and ROC AUC
    fpr, tpr, _ = roc_curve(y_test_bin, y_pred_proba)
    roc_auc = roc_auc_score(y_test_bin, y_pred_proba)
    roc_auc_scores.append(roc_auc)

    # Plot ROC curve
    ax1.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')

    # Compute precision-recall curve and PR AUC
    precision, recall, _ = precision_recall_curve(y_test_bin, y_pred_proba)
    pr_auc = auc(recall, precision)
    pr_auc_scores.append(pr_auc)

    # Plot precision-recall curve
    ax2.plot(recall, precision, label=f'{name} (AUC = {pr_auc:.2f})')

# Set labels and titles for ROC plot
ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
ax1.set_xlim([0.0, 1.0])
ax1.set_ylim([0.0, 1.05])
ax1.set_xlabel('False Positive Rate')
ax1.set_ylabel('True Positive Rate')
ax1.set_title('ROC Curve')
ax1.legend(loc="lower right")

# Set labels and titles for precision-recall plot
ax2.set_xlim([0.0, 1.0])
ax2.set_ylim([0.0, 1.05])
ax2.set_xlabel('Recall')
ax2.set_ylabel('Precision')
ax2.set_title('Precision-Recall Curve')
ax2.legend(loc="lower left")

# Show plots
plt.tight_layout()
plt.show()

# Display ROC AUC and PR AUC scores
print("ROC AUC Scores:")
for name, roc_auc in zip(model_names, roc_auc_scores):
    print(f"{name}: {roc_auc}")

print("\nPR AUC Scores:")
for name, pr_auc in zip(model_names, pr_auc_scores):
    print(f"{name}: {pr_auc}")